pub_date	title	venue	excerpt	citation	url_slug	paper_url
2016-09-01	Modelling Entailment with Neural Networks	MSc Thesis	This work is about modelling entailment with CNNs. We show that our approach achieves better results than the existing techniques and reducing the feature engineering requirements..	Davchev, Todor. (2016). Modelling Entailment with Neural Networks. <i>MSc Thesis</i>. University of Edinburgh.	modelling_entailment	http://tdavchev.github.io/files/MSc_Dissertation_Report.pdf
2019-05-07	An Empirical Evaluation of Adversarial Robustness under Transfer Learning.	International Conference on Machine Learning (ICML) 2019, workshop	This paper studies the effects of using robust optimisation in the context of adversarial attacks. This allows us to identify transfer learning strategies under which adversarial defences are successfully retained, in addition to revealing potential vulnerabilities.	Davchev, T., Korres, T., Fotiadis, S., Antonopoulos, N. and Ramamoorthy, S., 2019. An empirical evaluation of adversarial robustness under transfer learning. <i>Arxiv preprint</i>. arXiv:1905.02675.	adversarial-transfer	https://arxiv.org/pdf/1905.02675.pdf
2019-12-12	Vid2Param: Modelling of Dynamics Parameters from Video.	IEEE Robotics and Automation Letters	This work shows how models trained entirely in simulation, in an end-to-end manner can perform online system identification, and make probabilistic forward predictions of parameters of interest in the phyical world.	Asenov, M., Burke, M., Angelov, D., Davchev, T., Subr, K. and Ramamoorthy, S., 2019. Vid2Param: Modeling of Dynamics Parameters From Video. <i>IEEE Robotics and Automation Letters</i>, 5(2), pp.414-421.	vid-to-param	http://homepages.inf.ed.ac.uk/ksubr/Files/Papers/ICRA20Vid2Param.pdf
2020-08-18	Residual Learning from Demonstration.	arXiv preprint arXiv:2008.07682	In this work we propose residual learning from demonstration (rLfD), a framework that combines dynamic movement primitives (DMP) that rely on behavioural cloning with a reinforcement learning (RL) based residual correction policy.	Davchev, T., Luck, K.S., Burke, M., Meier, F., Schaal, S. and Ramamoorthy, S., 2020. Residual Learning from Demonstration. arXiv preprint arXiv:2008.07682.	residual-lfd	https://arxiv.org/pdf/2008.07682.pdf
2020-10-18	Model-Based Inverse Reinforcement Learning from Visual Demonstrations.	Conference on Robot Learning (CoRL) 2020	Scaling model-based inverse reinforcement learning (IRL) to real robotic manipulation tasks with unknown dynamics remains an open problem. The key challenges lie in learning good dynamics models, developing algorithms that scale to high-dimensional state-spaces and being able to learn from both visual and proprioceptive demonstrations. In this work, we present a gradient-based inverse reinforcement learning framework that utilizes a pre-trained visual dynamics model to learn cost functions when given only visual human demonstrations. The learned cost functions are then used to reproduce the demonstrated behavior via visual model predictive control. We evaluate our framework on hardware on two basic object manipulation tasks.	Das, N., Bechtle, S., Davchev, T., Jayaraman, D., Rai, A. and Meier, F., 2020. Model-Based Inverse Reinforcement Learning from Visual Demonstrations. <i> arXiv preprint <\i> arXiv:2010.09034.	mb-irl	https://arxiv.org/pdf/2010.09034.pdf
2021-01-21	Learning Structured Representations of Spatial and Interactive Dynamics for Trajectory Prediction in Crowded Scenes.	IEEE Robotics and Automation Letters, Special Issue on Long-term Human Motion Prediction	This paper is about learning modular methods that explictly allow for unsupervised adaptation of trajectory prediction models to unseen environments.	T. Davchev, M. Burke and S. Ramamoorthy, Learning Structured Representations of Spatial and Interactive Dynamics for Trajectory Prediction in Crowded Scenes. <i> in IEEE Robotics and Automation Letters </i>, vol. 6, no. 2, pp. 707-714, April 2021, doi: 10.1109/LRA.2020	structured-representations	https://ieeexplore.ieee.org/document/9309332?source=authoralert
